
# Build with AI Tools

## Overview

If you plan on using LLMs to assist in the building of SuperTokens integrations, reference this guide to improve your development experience.
The documentation has various helper tools that can aid you when you are interacting with different AI tools

## Text documentation

You can access all the documentation as plain text markdown files by appending `.md` to the end of any URL.
For example, you can find the plain text version of this page at [https://supertokens.com/docs/quickstart/build-with-ai-tools.md](https://supertokens.com/docs/quickstart/build-with-ai-tools.md).

This plain text format is ideal for AI tools and agents as it:
-  Contains fewer formatting tokens.
-  Displays content that might otherwise be hidden in the HTML or JavaScript-rendered version (such as content in tabs).
-  Maintains a clear markdown hierarchy that LLMs can easily parse and understand.

https://llmstxt.org

### `/llms.txt`

We also host an [/llms.txt file](https://docs.supertokens.com/llms.txt.md) which instructs AI tools and agents on how to retrieve the plain text versions of our pages. The `/llms.txt` file follows an [emerging standard](https://llmstxt.org/) for enhancing content accessibility to LLMs.


Additionally, our documentation pages feature buttons for copying the docs as markdown and for opening the full documentation page in an AI chat interface.

## Model Context Protocol (MCP) Server

You can use the SuperTokens Model Context Protocol (MCP) server if you use AI-enhanced code editors (such as Cursor or Windsurf) or general purpose tools like Claude Desktop.
The MCP server provides AI agents a suite of tools to call the SuperTokens API and search our knowledge base (documentation, support articles, and more).

For a local setup, you can run the [local SuperTokens MCP server](https://github.com/supertokens/agent-toolkit/tree/main/modelcontextprotocol).
